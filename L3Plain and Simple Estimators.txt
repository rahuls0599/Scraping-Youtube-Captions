We're going to train a simple classifier using only a handful lines of code. To train our classifier, we'll use TensorFlow, Google's open
source machine learning library. Estimators package up the training loop for us so that we can train a model by configuring it, rather than 
coding it by hand. And the first thing that we'll do is import TensorFlow as tf and numpy as np. I like to print out the version number of 
TensorFlow below to confirm which version I'm using. In particular, we'll be classifying different species of iris flowers. We have a dataset 
of measurements of the height and width of these flowers as petals and sepals. These four columns will serve as our features. So let's load our
dataset in using TensorFlow's load_csv with Header function. The data or features are presented as floating point numbers, and the label for 
each row of data or target is recorded as an integer-- 0, 1, or 2-- corresponding to our three species of flowers. Now I've printed out the 
results for our loading, and we can see that we are now able to access the trained data and the associated labels or targets using named 
attributes. Next, we'll build the model. To do this, we'll first set up the feature columns. Feature columns define the types of data coming 
into the model. We are using a four-dimensional feature column to represent our features, and calling them flower features. Building our model
using estimators is super simple. Using tf.estimators.LinearClassifier, we can instantiate the model by passing in the future columns we just 
created. The number of different outputs that the model predicts-- in this case, 3-- and a directory to store the model's training progress and
the output files. This allows TensorFlow to pick up training later on from where it left off, if needed. This classifier object will keep track
of state for us. And we are now almost ready to move on to the training. There is just one final piece to connect our model to the training 
data, and that is the input function. The job of the input function is to create the TensorFlow operations that generate data for the model. So
we go from raw data to the input function, which passes that data that is then mapped by the feature columns to go into the model. Notice that 
we use the same name for the features as we did in defining the feature column. This is how the data is associated. Now it's time to run our 
training. To train our model, we'll just run classifier.train with the input function passed in as an argument. This is how we connect our 
dataset to the model. The train function handles the training loop and iterates over the dataset, improving its performance with each step. And
just like that, we've completed 1,000 training steps. Our dataset's not huge, so this completed rather quickly. Now it's time to evaluate our 
results. We can do this using the same classifier object from before, as it holds the trained state of the model. To determine how good our 
model is, we run classifier.evaluate and pass in our test dataset. Then we can extract the accuracy from the metrics that are returned. 96.6%. 
OK. The estimator's API has given us a nice workflow of getting our raw data and passing it through an input function, setting up our feature 
columns and model structure, running our training, and finally, running our evaluation. This easy-to-understand framework allows us to think 
about our data and its properties, rather than the underlying math, which is a great place to be. 
